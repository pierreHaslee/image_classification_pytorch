{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torchattacks.attacks.autoattack import AutoAttack\n",
    "from torchattacks.attacks.bim import BIM\n",
    "from torchattacks.attacks.fgsm import FGSM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "import os\n",
    "\n",
    "from PizzaNet import PizzaNet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_data_path = '../../data/train'\n",
    "test_data_path = '../../data/test'\n",
    "\n",
    "IMG_SIZE = 512\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_data = ImageFolder(train_data_path, transform=trans)\n",
    "train_dataset, valid_dataset = random_split(train_data, lengths=[0.8,0.2])\n",
    "\n",
    "test_dataset = ImageFolder(test_data_path, transform=trans)\n",
    "test_dataset_fancy = ImageFolder(test_data_path, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PizzaNet(\n",
       "  (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=230400, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.35, inplace=False)\n",
       "  (soft): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path_load = f'saves{os.sep}latest_model_pizzanet.pickle'\n",
    "\n",
    "model = PizzaNet(512)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path_load))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = FGSM(model)\n",
    "#attack = AutoAttack(model, norm='Linf', n_classes=2, seed=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:33<00:00,  9.69it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4)\n",
    "\n",
    "adv_images = list()\n",
    "adv_labels = list()\n",
    "\n",
    "for i, (imgs, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "\n",
    "    imgs = imgs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    adv_images.append(attack(imgs, labels).to('cpu'))\n",
    "    adv_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attackDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        super(attackDataset, self).__init__()\n",
    "        self.imgs = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.imgs[index], self.labels[index])\n",
    "\n",
    "adv_loader = DataLoader(attackDataset(torch.cat([*adv_images]), torch.cat([*adv_labels])), batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    \n",
    "    f1 = torchmetrics.F1Score(task='binary', average='macro')\n",
    "    model.eval()\n",
    "    total_size = 0\n",
    "\n",
    "    predicted = []\n",
    "    targets = []\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            \n",
    "            labels = labels.type(torch.LongTensor).to(device)\n",
    "            predicted_labels = model(inputs.to(device)).squeeze()\n",
    "            \n",
    "            losses.append(float(criterion(predicted_labels, labels).to('cpu').item()))\n",
    "            \n",
    "            predicted.append(predicted_labels.to('cpu'))\n",
    "            targets.append(labels.to('cpu'))\n",
    "            \n",
    "            total_size += labels.size(0)\n",
    "\n",
    "    predicted = torch.cat([*predicted])\n",
    "    targets = torch.cat([*targets])\n",
    "\n",
    "    accuracy = (predicted.argmax(1) == targets).sum().item()/total_size\n",
    "\n",
    "    f1score = f1(predicted.argmax(1), targets)\n",
    "    return accuracy, f1score, sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.86484375 | f1-score: 0.8571428656578064 | loss: 0.44866748647764326\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_f1, train_loss = evaluate(model, DataLoader(train_dataset, batch_size=4))\n",
    "print('train accuracy: {} | f1-score: {} | loss: {}'.format(train_acc, train_f1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADV accuracy: 0.609375 | f1-score: 0.4369369447231293 | loss: 0.6660731438547373\n"
     ]
    }
   ],
   "source": [
    "adv_acc, adv_f1, adv_loss = evaluate(model, adv_loader)\n",
    "print('ADV accuracy: {} | f1-score: {} | loss: {}'.format(adv_acc, adv_f1, adv_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f6492f7c23caa7df8217a480c5966940e09a36b9779b2b7a716a923cbdfee5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
